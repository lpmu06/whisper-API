# Whisper-API

API REST desenvolvida com FastAPI para transcriÃ§Ã£o de Ã¡udio para texto utilizando o modelo Whisper da OpenAI. A API Ã© containerizada usando Docker e otimizada para transcriÃ§Ãµes em portuguÃªs brasileiro.

## ğŸš€ Funcionalidades

- TranscriÃ§Ã£o de Ã¡udio para texto usando o modelo Whisper
- Suporte para mÃºltiplos arquivos de Ã¡udio
- Otimizado para portuguÃªs brasileiro
- Interface Swagger UI para testes (/docs)
- Suporte a GPU (CUDA) quando disponÃ­vel

## ğŸ“‹ PrÃ©-requisitos

- Docker
- Git
- (Opcional) NVIDIA GPU com CUDA para melhor performance

## ğŸ”§ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone <https://github.com/lpmu06/whisper-API>
cd whisper-api
```

### 2. Construa a imagem Docker
```bash
docker build -t whisper-api .
```

### 3. Execute o container
```bash
docker run -d -p 8000:8000 whisper-api
```

A API estarÃ¡ disponÃ­vel em `http://localhost:8000`

## ğŸ“ Como Usar

### Endpoint Principal

- **URL**: `/whisper`
- **MÃ©todo**: `POST`
- **Content-Type**: `multipart/form-data`

### Exemplo de uso com cURL
```bash
curl -X POST "http://localhost:8000/whisper" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "files=@seu_audio.mp3"
```

### Exemplo de uso com Python
```python
import requests

url = "http://localhost:8000/whisper"
files = [
    ('files', ('audio.mp3', open('audio.mp3', 'rb'), 'audio/mpeg'))
]

response = requests.post(url, files=files)
print(response.json())
```

### Formatos de Ãudio Suportados
- MP3 (.mp3)
- WAV (.wav)
- Outros formatos suportados pelo ffmpeg

### Resposta
A API retorna um JSON no seguinte formato:
```json
{
    "results": [
        {
            "filename": "audio.mp3",
            "transcript": "Texto transcrito do Ã¡udio..."
        }
    ]
}
```

## ğŸ” Testando a API

1. Acesse a documentaÃ§Ã£o Swagger UI em `http://localhost:8000/docs`
2. Expanda o endpoint POST `/whisper`
3. Clique em "Try it out"
4. FaÃ§a upload de um arquivo de Ã¡udio
5. Execute e verifique a resposta

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente
- `PORT`: Porta da aplicaÃ§Ã£o (default: 8000)
- Outras configuraÃ§Ãµes podem ser adicionadas conforme necessidade

### Usando GPU
A API automaticamente detecta e utiliza GPU se disponÃ­vel. Para usar com GPU:

1. Instale os drivers NVIDIA
2. Instale o NVIDIA Container Toolkit
3. Execute o container com suporte a GPU:
```bash
docker run --gpus all -d -p 8000:8000 whisper-api
```

## ğŸ› ï¸ Desenvolvimento

### Estrutura do Projeto

whisper-api/
â”œâ”€â”€ fastapi_app.py    # AplicaÃ§Ã£o principal
â”œâ”€â”€ requirements.txt  # DependÃªncias Python
â”œâ”€â”€ Dockerfile       # ConfiguraÃ§Ã£o Docker
â””â”€â”€ README.md       # DocumentaÃ§Ã£o


### DependÃªncias Principais
- FastAPI
- Uvicorn
- OpenAI Whisper
- PyTorch
- python-multipart
- aiofiles

## ğŸ“ˆ Performance

- O modelo base do Whisper Ã© usado por padrÃ£o
- Para melhor precisÃ£o em portuguÃªs, considere usar modelos maiores (medium/large)
- O tempo de processamento varia conforme o hardware e tamanho do Ã¡udio

## âœ¨ PrÃ³ximos Passos

- [ ] Implementar limite de tamanho de arquivo
- [ ] Implementar sistema de filas para processamento assÃ­ncrono
- [ ] Adicionar mais opÃ§Ãµes de configuraÃ§Ã£o do modelo Whisper
- [ ] Implementar validaÃ§Ã£o de tipos de arquivo
- [ ] Otimizar configuraÃ§Ãµes para portuguÃªs brasileiro
- [ ] Adicionar tratamento de erros mais robusto
- [ ] Implementar rate limiting
- [ ] Adicionar suporte a variÃ¡veis de ambiente