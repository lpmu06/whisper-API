# Whisper-API

API REST desenvolvida com FastAPI para transcriÃ§Ã£o de Ã¡udio para texto utilizando o modelo Whisper da OpenAI. A API Ã© containerizada usando Docker e otimizada para transcriÃ§Ãµes em portuguÃªs brasileiro.

## ğŸš€ Funcionalidades

- TranscriÃ§Ã£o de Ã¡udio para texto usando o modelo Whisper
- Suporte para mÃºltiplos arquivos de Ã¡udio
- Otimizado para portuguÃªs brasileiro
- Interface Swagger UI para testes (/docs)
- Suporte a GPU (CUDA) quando disponÃ­vel
- ValidaÃ§Ã£o de arquivos e tratamento de erros
- Healthcheck endpoint

## ğŸ“‹ PrÃ©-requisitos

- Docker
- Docker Compose
- Git
- (Opcional) NVIDIA GPU com CUDA para melhor performance

## ğŸ”§ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/lpmu06/whisper-API
cd whisper-api
```

### 2. Execute com Docker Compose
```bash
docker-compose up --build
```

A API estarÃ¡ disponÃ­vel em `http://localhost:8000`

## ğŸ“ Como Usar

### Endpoint Principal

- **URL**: `/transcribe`  # Atualizado de /whisper para /transcribe
- **MÃ©todo**: `POST`
- **Content-Type**: `multipart/form-data`

### Exemplo de uso com cURL
```bash
curl -X POST "http://localhost:8000/transcribe" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "files=@seu_audio.mp3"
```

### Exemplo de uso com Python
```python
import requests

url = "http://localhost:8000/transcribe"
files = [
    ('files', ('audio.mp3', open('audio.mp3', 'rb'), 'audio/mpeg'))
]

response = requests.post(url, files=files)
print(response.json())
```

### Formatos de Ãudio Suportados
- MP3 (.mp3)
- WAV (.wav)
- M4A (.m4a)
- OGG (.ogg)

### LimitaÃ§Ãµes
- Tamanho mÃ¡ximo do arquivo: 25MB
- Apenas formatos de Ã¡udio suportados serÃ£o aceitos

### Resposta
A API retorna um JSON no seguinte formato:
```json
{
    "results": [
        {
            "filename": "audio.mp3",
            "transcript": "Texto transcrito do Ã¡udio..."
        }
    ]
}
```

## ğŸ” Testando a API

1. Acesse a documentaÃ§Ã£o Swagger UI em `http://localhost:8000/docs`
2. Expanda o endpoint POST `/transcribe`
3. Clique em "Try it out"
4. FaÃ§a upload de um arquivo de Ã¡udio
5. Execute e verifique a resposta

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente
- `WHISPER_MODEL`: Modelo Whisper a ser usado (default: "base")
  ```bash
  # Exemplo: usar modelo medium
  WHISPER_MODEL=medium docker-compose up

  # Modelos disponÃ­veis:
  # - tiny
  # - base
  # - small
  # - medium
  # - large
  ```
- `MAX_FILE_SIZE_MB`: Tamanho mÃ¡ximo do arquivo em MB (default: 25)
- `LANGUAGE`: Idioma para transcriÃ§Ã£o (default: "pt")

### Usando GPU
A API automaticamente detecta e utiliza GPU se disponÃ­vel. Para usar com GPU:

1. Instale os drivers NVIDIA
2. Instale o NVIDIA Container Toolkit
3. Execute com Docker Compose (configuraÃ§Ã£o GPU jÃ¡ incluÃ­da)

## ğŸ› ï¸ Desenvolvimento

### Estrutura do Projeto

whisper-api/
â”œâ”€â”€ app/

â”‚   â”œâ”€â”€ main.py         # AplicaÃ§Ã£o principal

â”‚   â”œâ”€â”€ config.py       # ConfiguraÃ§Ãµes

â”‚   â””â”€â”€ transcriber.py  # LÃ³gica de transcriÃ§Ã£o

â”œâ”€â”€ requirements.txt    # DependÃªncias Python

â”œâ”€â”€ Dockerfile         # ConfiguraÃ§Ã£o Docker

â”œâ”€â”€ docker-compose.yml # ConfiguraÃ§Ã£o Docker Compose

â””â”€â”€ README.md         # DocumentaÃ§Ã£o


### DependÃªncias Principais
- FastAPI (0.104.1)
- Uvicorn (0.15.0)
- OpenAI Whisper
- PyTorch (2.1.2)
- NumPy (1.24.3)
- python-multipart (0.0.6)
- aiofiles (23.2.1)
- pydantic (2.5.3)
- pydantic-settings (2.1.0)

## ğŸ“ˆ Performance

- O modelo base do Whisper Ã© usado por padrÃ£o
- Para melhor precisÃ£o em portuguÃªs, considere usar modelos maiores (medium/large)
- O tempo de processamento varia conforme o hardware e tamanho do Ã¡udio
- Em CPU, o modelo usa precisÃ£o FP32
- Em GPU, o modelo usa precisÃ£o FP16 para melhor performance

## âœ¨ Melhorias Implementadas

- [x] Implementar limite de tamanho de arquivo (25MB)
- [x] Implementar validaÃ§Ã£o de tipos de arquivo
- [x] Otimizar configuraÃ§Ãµes para portuguÃªs brasileiro
- [x] Adicionar tratamento de erros
- [x] Adicionar suporte a variÃ¡veis de ambiente
- [x] Adicionar healthcheck endpoint
- [x] Especificar versÃµes das dependÃªncias
- [x] Otimizar configuraÃ§Ã£o do Docker

## ğŸ”œ PrÃ³ximos Passos

- [ ] Implementar sistema de filas para processamento assÃ­ncrono
- [ ] Adicionar mais opÃ§Ãµes de configuraÃ§Ã£o do modelo Whisper
- [ ] Implementar rate limiting
- [ ] Adicionar sistema de cache para otimizaÃ§Ã£o
- [ ] Implementar autenticaÃ§Ã£o e autorizaÃ§Ã£o
- [ ] Adicionar mÃ©tricas e monitoramento
- [ ] Implementar logs estruturados
- [ ] Adicionar testes automatizados